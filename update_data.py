import requests
import pandas as pd
import sys
import datetime
import json

# ×”×’×“×¨×ª ×§×™×“×•×“ ×œ×”×“×¤×¡×ª ×¢×‘×¨×™×ª ×ª×§×™× ×” ×‘×œ×•×’×™×
if sys.stdout.encoding != 'utf-8':
    sys.stdout.reconfigure(encoding='utf-8')

def find_alive_resource():
    """
    ×¤×•× ×§×¦×™×” ×–×• ×¡×•×¨×§×ª ××ª ×”×××’×¨ ×”×××©×œ×ª×™ ×¢× ××¡×¤×¨ ××™×œ×•×ª ××¤×ª×—
    ×•××—×–×™×¨×” ××ª ×”-Resource ID ×”×¨××©×•×Ÿ ×©×‘×××ª ×¢×•×‘×“ ×•××—×–×™×¨ × ×ª×•× ×™×.
    """
    print("--- ğŸ•µï¸ Starting Intelligent Resource Discovery ---")
    
    # ×¨×©×™××ª ××™×œ×•×ª ××¤×ª×— ×œ×—×™×¤×•×© ×¨×—×‘ ×›×“×™ ×œ× ×œ×¤×¡×¤×¡ ××ª ×”×××’×¨
    search_terms = ["×¢×¡×§××•×ª × ×“×œ×Ÿ", "× ×“×œ×Ÿ", "Real Estate", "Transactions", "×›×¨××Ÿ"]
    base_search_url = "https://data.gov.il/api/3/action/package_search"
    base_data_url = "https://data.gov.il/api/3/action/datastore_search"
    
    candidates = []

    # ×©×œ×‘ 1: ××™×¡×•×£ ××•×¢××“×™×
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
    
    for term in search_terms:
        try:
            print(f"ğŸ” Searching for keyword: '{term}'...")
            params = {'q': term, 'rows': 5}
            response = requests.get(base_search_url, params=params, headers=headers, timeout=10)
            
            if response.status_code == 200:
                results = response.json().get('result', {}).get('results', [])
                for pkg in results:
                    for res in pkg.get('resources', []):
                        # ×¡×™× ×•×Ÿ ×’×¡: ×× ×—× ×• ××—×¤×©×™× ×§×‘×¦×™ CSV ×¨×œ×•×•× ×˜×™×™×
                        if 'CSV' in res.get('format', '').upper():
                            candidates.append({
                                'name': res.get('name', 'Unknown'),
                                'id': res['id'],
                                'pkg_title': pkg.get('title', 'Unknown')
                            })
        except Exception as e:
            print(f"âš ï¸ Search error for '{term}': {e}")

    # ×”×¡×¨×ª ×›×¤×™×œ×•×™×•×ª
    unique_candidates = {v['id']: v for v in candidates}.values()
    print(f"ğŸ“‹ Found {len(unique_candidates)} potential resources. Testing connectivity...")

    # ×©×œ×‘ 2: ×‘×“×™×§×ª "×“×•×¤×§" ×œ×›×œ ××•×¢××“
    for cand in unique_candidates:
        res_id = cand['id']
        name = cand['name']
        print(f"ğŸ‘‰ Testing ID: {res_id} ({name})...", end=" ")
        
        try:
            # ×× ×¡×™× ×œ×©×œ×•×£ ×¨×§ ×©×•×¨×” ××—×ª ×›×“×™ ×œ×¨××•×ª ×× ×”×©×¨×ª ××’×™×‘
            test_url = f"{base_data_url}?resource_id={res_id}&limit=1"
            resp = requests.get(test_url, headers=headers, timeout=15)
            
            if resp.status_code == 200:
                data = resp.json()
                if data.get('success') and data.get('result', {}).get('records'):
                    print("âœ… ALIVE! Found valid data.")
                    return res_id
                else:
                    print("âŒ Empty response.")
            else:
                print(f"âŒ Error {resp.status_code}")
        except Exception as e:
            print(f"âŒ Exception: {e}")

    print("ğŸ’€ All searches failed. No alive resource found.")
    return None

def fetch_data():
    # ×—×™×¤×•×© ×”××–×”×” ×”×—×™
    resource_id = find_alive_resource()
    
    if not resource_id:
        print("âŒ CRITICAL: Could not find any active Real Estate resource ID.")
        # ×”×“×¤×¡×ª ×›×œ ×”××•×¢××“×™× ×œ×œ×•×’ ×›×“×™ ×©×ª×•×›×œ ×œ×©×œ×•×— ×œ×™ ×œ× ×™×ª×•×— ×× ×–×” × ×›×©×œ
        sys.exit(1)

    # ×‘×™×¦×•×¢ ×”×©×œ×™×¤×” ×”××œ××” ×¢× ×”××–×”×” ×©× ××¦×
    url = f"https://data.gov.il/api/3/action/datastore_search?resource_id={resource_id}&limit=32000"
    
    try:
        print(f"--- ğŸš€ Starting Full Fetch from Verified ID: {resource_id} ---")
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'}
        response = requests.get(url, headers=headers, timeout=120)
        
        if response.status_code == 200:
            records = response.json().get('result', {}).get('records', [])
            if records:
                df = pd.DataFrame(records)
                
                # ×”×“×¤×¡×ª ×¢××•×“×•×ª ×œ×œ×•×’ ×œ×¦×•×¨×š ×“×™×‘××’×™× ×’
                print(f"Columns found: {list(df.columns)}")
                
                # ×¡×™× ×•×Ÿ ×—×›×: ××¦×™××ª ×¢××•×“×ª ×”×™×™×©×•×‘ ×‘××•×¤×Ÿ ×“×™× ××™ (×œ××§×¨×” ×©×”×©× ×”×©×ª× ×”)
                city_col = next((col for col in df.columns if '×™×™×©×•×‘' in col or 'city' in col.lower()), None)
                
                if city_col:
                    df_tlv = df[df[city_col].astype(str).str.contains('×ª×œ ××‘×™×‘', na=False)].copy()
                    filename = "tlv_deals_master.csv"
                    df_tlv.to_csv(filename, index=False, encoding='utf-8-sig')
                    print(f"âœ… SUCCESS! Saved {len(df_tlv)} Tel Aviv deals to {filename}")
                else:
                    print("âš ï¸ Could not identify 'City' column. Saving raw file...")
                    df.to_csv("raw_data_debug.csv", index=False, encoding='utf-8-sig')
            else:
                print("âŒ API returned 0 records.")
        else:
            print(f"âŒ Full fetch failed: {response.status_code}")
            sys.exit(1)
            
    except Exception as e:
        print(f"âŒ Critical Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    fetch_data()
